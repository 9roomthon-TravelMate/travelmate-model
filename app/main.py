
from fastapi import FastAPI, Depends, HTTPException, Query
from sqlalchemy.orm import Session
from app import crud
from app import models
from app.database import SessionLocal, engine
from app.recommendation import recommend_locations_hybrid1
from app.preprocessing import preprocess_data
from dotenv import load_dotenv
from contextlib import asynccontextmanager
import pandas as pd
import os
import psutil
import sys
import logging
import numpy as np
import gc

# âœ… ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

load_dotenv() 

models.Base.metadata.create_all(bind=engine)

CHUNK_SIZE = 5000 # ì²­í¬ í¬ê¸° ì„¤ì •(í˜„ì¬ ì•½ 48000ê°œì˜ ë°ì´í„° ì¡´ì¬)

app = FastAPI()

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# @asynccontextmanager
# async def lifespan(app: FastAPI):
#     global content_embeddings
#     s3 = boto3.client('s3')
#     s3.download_file('travel-mate-model-server', 'model/visited_embedding.csv', 'visited_embedding.csv')
#     content_embeddings = pd.read_csv('visited_embedding.csv', index_col='contentid')
#     yield
#     os.remove('visited_embedding.csv')

def load_content_embeddings():
    file_path = "visited_embedding.csv"
    if not os.path.exists(file_path):
        raise RuntimeError(f"Error: {file_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    logger.info(f"ğŸ“Œ {file_path} íŒŒì¼ì„ chunk ë‹¨ìœ„({CHUNK_SIZE})ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.")
    return pd.read_csv(file_path, index_col='contentid', chunksize=CHUNK_SIZE)


def generate_similarity_matrices(db: Session, traveler_id: int = None, region_id: int = None):
    preferences = crud.get_all_preferences(db, traveler_id=traveler_id, region_id=region_id)
    visited = crud.get_all_visited(db, region_id)

    df_traveller = pd.DataFrame([{
        'traveler_id': pref.traveler_id,
        'gender': pref.gender,
        'age_grp': pref.age_grp,
        'travel_start_ymd': pref.travel_start_ymd,
        'travel_end_ymd': pref.travel_end_ymd,
        'travel_styl_1': pref.travel_styl_1,
        'travel_styl_2': pref.travel_styl_2,
        'travel_styl_3': pref.travel_styl_3,
        'travel_styl_4': pref.travel_styl_4,
        'travel_styl_5': pref.travel_styl_5,
        'travel_styl_6': pref.travel_styl_6,
        'travel_styl_7': pref.travel_styl_7,
        'travel_companions_num': pref.travel_companions_num
    } for pref in preferences]) if preferences else pd.DataFrame()

    df_visited = pd.DataFrame([{
        'traveler_id': visit.traveler_id,
        'content_id': visit.content_id
    } for visit in visited]) if visited else pd.DataFrame()

    if df_traveller.empty or df_visited.empty:
        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()
    
    return preprocess_data(df_traveller, df_visited)

@app.get("/recommend/{traveler_id}")
def get_recommendations(traveler_id: int, region_id: int = Query(None), n_recommendations: int = 20, db: Session = Depends(get_db)):
    try:
        process = psutil.Process()
        mem_before = process.memory_info().rss / 1024 ** 2  
        peak_mem = mem_before  

        logger.info(f" traveler_id={traveler_id}, region_id={region_id} ì¶”ì²œ ì‹œì‘")
        logger.info(f" API í˜¸ì¶œ ì „ ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {mem_before:.2f} MB")

        recommendations_with_scores = []

        for i, chunk in enumerate(load_content_embeddings()):
           
            mem_after_chunk_load = process.memory_info().rss / 1024 ** 2
            logger.info(f" [{i+1}ë²ˆì§¸ ì²­í¬] ë¡œë“œ ì™„ë£Œ (í¬ê¸°: {len(chunk)}) | ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {mem_after_chunk_load:.2f} MB")

            if region_id is not None:
                chunk = chunk[chunk['areacode'] == region_id]
            
            mem_after_filtering = process.memory_info().rss / 1024 ** 2
            logger.info(f"[{i+1}ë²ˆì§¸ ì²­í¬] í•„í„°ë§ í›„ í¬ê¸°: {len(chunk)} | ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {mem_after_filtering:.2f} MB")

            if chunk.empty:
                continue  

            df_traveller_encoded, visit_matrix, combined_similarity_df = generate_similarity_matrices(db, traveler_id=traveler_id, region_id=region_id)

            if df_traveller_encoded.empty or visit_matrix.empty or combined_similarity_df.empty:
                continue  

            visit_matrix_np = visit_matrix.to_numpy(dtype=np.float32, copy=False)

            logger.info(f"[{i+1}ë²ˆì§¸ ì²­í¬] traveler_id={traveler_id} ì¶”ì²œ ìˆ˜í–‰ (ìµœì¢… ì²­í¬ í¬ê¸°: {len(chunk)})")

            chunk_recommendations = recommend_locations_hybrid1(traveler_id, combined_similarity_df, visit_matrix_np, chunk, n_recommendations)
            recommendations_with_scores.extend(chunk_recommendations)

            mem_after_chunk_process = process.memory_info().rss / 1024 ** 2
            logger.info(f"[{i+1}ë²ˆì§¸ ì²­í¬] ì¶”ì²œ ìˆ˜í–‰ í›„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {mem_after_chunk_process:.2f} MB")

            gc.collect()
            # mem_after_gc = process.memory_info().rss / 1024 ** 2
            # logger.info(f" [{i+1}ë²ˆì§¸ ì²­í¬] GC ì‹¤í–‰ í›„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {mem_after_gc:.2f} MB")

            if mem_after_chunk_process > peak_mem:
                peak_mem = mem_after_chunk_process  # âœ… í”¼í¬ ë©”ëª¨ë¦¬ ê°±ì‹ 

        recommendations_with_scores.sort(key=lambda x: x[1], reverse=True)
        recommendations = [content_id for content_id, _ in recommendations_with_scores][:n_recommendations]

        mem_after = process.memory_info().rss / 1024 ** 2
        logger.info(f" traveler_id={traveler_id} ì¶”ì²œ ì™„ë£Œ!")
        logger.info(f" API í˜¸ì¶œ í›„ ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {mem_after:.2f} MB")
        logger.info(f" ì „ì²´ ì²˜ë¦¬ ì¤‘ ìµœê³  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {peak_mem:.2f} MB")

        if not recommendations:
            raise HTTPException(status_code=404, detail="No recommendations available")

        return {
            "traveler_id": traveler_id,
            "recommendations": recommendations,
            "system_memory_before": f"{mem_before:.2f} MB",
            "system_memory_after": f"{mem_after:.2f} MB",
            "peak_system_memory": f"{peak_mem:.2f} MB"
        }

    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))



if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="127.0.0.1", port=8000)
